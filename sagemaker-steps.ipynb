{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "85f538a6e822c93fbd1323f394234a4f1b14a39243c0ebd5ef6d3ff33fa65f0c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SageMaker - Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure AWS CLI\r\n",
    "\r\n",
    "Refs: \r\n",
    "- <a href='https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-creds'>To create access key for an IAM user</a>\r\n",
    "- <a href='https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html'>CLI Configure QuickStart</a>\r\n",
    "\r\n",
    "For execute this notebook you need configure aws cli with your credentials\r\n",
    "\r\n",
    "User Policies:\r\n",
    "- AdministratorAccess\r\n",
    "- AmazonSageMakerFullAccess\r\n",
    "\r\n",
    "Functions for SageMaker:\r\n",
    "- AmazonS3FullAccess\r\n",
    "- AmazonSageMakerFullAccess"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After configure your AWS credentials, execute the script build_and_push.sh to build docker image and registry on AWS ECR\r\n",
    "\r\n",
    "> build_and_push.sh iris-logistic-regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SageMaker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import boto3, re, os\r\n",
    "import pandas as pd\r\n",
    "from sagemaker import get_execution_role\r\n",
    "import sagemaker as sage\r\n",
    "from time import gmtime, strftime\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\r\n",
    "from sagemaker.predictor import csv_serializer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data between train and validation\r\n",
    "\r\n",
    "After split dataset (train and validation), upload the files in your s3 bucket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Data location\r\n",
    "local_path = 'local_test/test_dir/input/data/{}'\r\n",
    "\r\n",
    "# Load dataset\r\n",
    "data = pd.read_csv(local_path.format('training/iris.csv'))\r\n",
    "\r\n",
    "# Split train and validation\r\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=1)\r\n",
    "\r\n",
    "# Write datasets\r\n",
    "X_train.to_csv(local_path.format('training.csv'), index=False)\r\n",
    "X_test.to_csv(local_path.format('validation.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a Debugger built-in rule list object\r\n",
    "\r\n",
    "The following code cell shows how to configure a rule object for debugging and profiling. For more information about the Debugger built-in rules, see <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html\">List of Debugger Built-in Rules</a>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "built_in_rules = [\r\n",
    "    Rule.sagemaker(rule_configs.overfit()),\r\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Session, an estimator and fit the model\r\n",
    "\r\n",
    "In order to use SageMaker to fit our algorithm, we'll create an Estimator that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\r\n",
    "\r\n",
    "- The **container name.** This is constructed as in the shell commands above.\r\n",
    "- The **role.** As defined above.\r\n",
    "- The **instance count** which is the number of machines to use for training.\r\n",
    "- The **instance type** which is the type of machine to use for training.\r\n",
    "- The **output path** determines where the model artifact will be written.\r\n",
    "- The **session** is the SageMaker session object that we defined above.\r\n",
    "\r\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Create the session\r\n",
    "sess = sage.Session()\r\n",
    "\r\n",
    "# Get IAM Functions for SageMaker\r\n",
    "role = 'arn:aws:iam::465270637007:role/AmazonSageMaker-ExecutionRole' #get_execution_role()\r\n",
    "\r\n",
    "# Create an estimator\r\n",
    "prefix = \"logistic-regression\" # S3 prefix\r\n",
    "data_location = \"s3://logistic-regression/iris.csv\"\r\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\r\n",
    "region = sess.boto_session.region_name\r\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/iris-logistic-regression:latest\".format(account, region)\r\n",
    "instance_count = 1\r\n",
    "instance_type = \"ml.m5.xlarge\"\r\n",
    "output_path = \"s3://{}/output\".format(prefix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Create estimator\r\n",
    "model = sage.estimator.Estimator(\r\n",
    "    image_uri=image,\r\n",
    "    role=role,\r\n",
    "    instance_count=instance_count,\r\n",
    "    instance_type=instance_type,\r\n",
    "    output_path=output_path,\r\n",
    "    sagemaker_session=sess,\r\n",
    "    rules=built_in_rules\r\n",
    ")\r\n",
    "# Fit model\r\n",
    "model.fit(data_location)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-07-27 23:07:59 Starting - Starting the training job...\n",
      "2021-07-27 23:08:31 Starting - Launching requested ML instancesOverfit: InProgress\n",
      "ProfilerReport: InProgress\n",
      "...\n",
      "2021-07-27 23:09:02 Starting - Preparing the instances for training......\n",
      "2021-07-27 23:10:14 Downloading - Downloading input data\n",
      "2021-07-27 23:10:14 Training - Downloading the training image...\n",
      "2021-07-27 23:10:43 Uploading - Uploading generated training model\n",
      "2021-07-27 23:10:43 Completed - Training job completed\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "Training seconds: 40\n",
      "Billable seconds: 40\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "predictor = model.deploy(1, instance_type, serializer=csv_serializer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------!"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "predictor.predict([7,3.2,4.7,1.4])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'versicolor\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delete Endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![title](img/sagemaker-painel.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Important refs:\r\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html\r\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\r\n",
    "- https://aws.amazon.com/pt/blogs/machine-learning/build-end-to-end-machine-learning-workflows-with-amazon-sagemaker-and-apache-airflow/"
   ],
   "metadata": {}
  }
 ]
}